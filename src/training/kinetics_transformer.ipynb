{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f205ea0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import clip\n",
    "import einops\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import webdataset as wds\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from einops import rearrange, repeat\n",
    "from torch import nn, einsum\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d230dcf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: clip in ./.local/lib/python3.8/site-packages (0.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.8/site-packages (1.12.0+cu113)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.8/site-packages (0.13.0+cu113)\n",
      "Requirement already satisfied: torchaudio in ./.local/lib/python3.8/site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from torchvision) (1.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.8/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.8/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.8/site-packages (from requests->torchvision) (1.26.9)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: webdataset in ./.local/lib/python3.8/site-packages (0.2.5)\n",
      "Requirement already satisfied: braceexpand in ./.local/lib/python3.8/site-packages (from webdataset) (0.1.7)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from webdataset) (1.23.0)\n",
      "Requirement already satisfied: pyyaml in ./.local/lib/python3.8/site-packages (from webdataset) (6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in ./.local/lib/python3.8/site-packages (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.8/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.local/lib/python3.8/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: einops in ./.local/lib/python3.8/site-packages (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3.8 install git+https://github.com/openai/CLIP.git\n",
    "!pip3.8 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "!pip3.8 install webdataset\n",
    "!pip3.8 install pandas\n",
    "!pip3.8 install einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d5769",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "793e2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset code:\n",
    "\"\"\"\n",
    "utils for processing datasets of format described in https://github.com/iejMac/clip-video-encode/pull/13\n",
    "used https://github.com/rom1504/laion-prepro/blob/main/laion5B/usage_guide/dataloader_pytorch.py as template\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def standardize_embedding_shape(emb, seq_len):\n",
    "    if len(emb) > seq_len:\n",
    "        print(f\"Warning: Raw embedding is longer than standard sequence length ({len(emb)} > {seq_len})\")\n",
    "        emb = emb[:seq_len]\n",
    "\n",
    "    pad = np.zeros((seq_len - len(emb), emb.shape[1]), dtype=emb.dtype)\n",
    "    padded_emb = np.concatenate([emb, pad])\n",
    "    return padded_emb\n",
    "\n",
    "\n",
    "def create_embeddingwebdataset(\n",
    "    urls,\n",
    "    embedding_transform=lambda emb: emb,\n",
    "    standard_seq_len=-1,\n",
    "    to_tensor=True,\n",
    "    enable_text=True,\n",
    "    enable_meta=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a WebDataset reader for Frame Embedding Dataset\n",
    "    Input:\n",
    "        standard_seq_len: sequence length to pad all embedding sequences to (for batching)\n",
    "            !(-1) : pad to standard_seq_len\n",
    "            -1: don't pad (dataset can't be used in DataLoader with batch_size > 1)\n",
    "        enable_text: include text captions\n",
    "        enable_meta: include metadata\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = wds.WebDataset(urls)\n",
    "    # TODO: different tokeinzers??\n",
    "    tokenizer = lambda text: clip.tokenize([text], truncate=True)[0]\n",
    "\n",
    "    def preprocess_dataset(item):\n",
    "        output = {}\n",
    "\n",
    "        npy_data = item[\"npy\"]\n",
    "        stream = io.BytesIO(npy_data)\n",
    "        emb = np.lib.format.read_array(stream)\n",
    "\n",
    "        if standard_seq_len != -1:\n",
    "            emb = standardize_embedding_shape(emb, standard_seq_len)\n",
    "        if to_tensor:\n",
    "            emb = torch.from_numpy(emb)\n",
    "\n",
    "        output[\"embeddings\"] = embedding_transform(emb)\n",
    "\n",
    "        if enable_text:\n",
    "            text_data = item[\"cap\"]\n",
    "            text = text_data.decode(\"utf-8\")\n",
    "            output[\"text\"] = text\n",
    "            output[\"text_tokens\"] = tokenizer(text)\n",
    "        if enable_meta:\n",
    "            meta_data = item[\"json\"]\n",
    "            meta = meta_data.decode(\"utf-8\")\n",
    "            output[\"meta\"] = meta\n",
    "        return output\n",
    "\n",
    "    transformed_dataset = dataset.map(preprocess_dataset, handler=wds.handlers.warn_and_continue)\n",
    "    return transformed_dataset\n",
    "\n",
    "\n",
    "def dataset_to_dataloader(dataset, batch_size, num_prepro_workers):\n",
    "    \"\"\"converts WebDataset to PyTorch DataLoader.\"\"\"\n",
    "\n",
    "    dl = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_prepro_workers,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "    )\n",
    "\n",
    "    return dl\n",
    "\n",
    "\n",
    "class EmbeddingWebDatasetReader:\n",
    "    \"\"\"WebDataset reader for Embedding Datasets\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        urls,\n",
    "        standard_seq_len,\n",
    "        batch_size,\n",
    "        num_prepro_workers,\n",
    "        to_tensor=True,\n",
    "        enable_text=True,\n",
    "        enable_meta=False,\n",
    "        embedding_transform=lambda emb: emb,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        dataset = create_embeddingwebdataset(\n",
    "            urls,\n",
    "            embedding_transform,\n",
    "            standard_seq_len,\n",
    "            to_tensor,\n",
    "            enable_text,\n",
    "            enable_meta,\n",
    "        )\n",
    "        self.dataloader = dataset_to_dataloader(dataset, batch_size, num_prepro_workers)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38a92d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26ac12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross attention - using multi-query + one-headed key / values as in PaLM w/ optional parallel feedforward\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.register_buffer(\"beta\", torch.zeros(dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, x.shape[-1:], self.gamma, self.beta)\n",
    "    \n",
    "    \n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        context_dim=None,\n",
    "        dim_head=64,\n",
    "        heads=8,\n",
    "        parallel_ff=False,\n",
    "        ff_mult=4,\n",
    "        norm_context=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "        inner_dim = heads * dim_head\n",
    "        context_dim = default(context_dim, dim)\n",
    "\n",
    "        self.norm = LayerNorm(dim)\n",
    "        self.context_norm = LayerNorm(context_dim) if norm_context else nn.Identity()\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
    "        self.to_kv = nn.Linear(context_dim, dim_head * 2, bias=False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim, bias=False)\n",
    "\n",
    "        # whether to have parallel feedforward\n",
    "\n",
    "        ff_inner_dim = ff_mult * dim\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(dim, ff_inner_dim * 2, bias=False),\n",
    "            SwiGLU(),\n",
    "            nn.Linear(ff_inner_dim, dim, bias=False)\n",
    "        ) if parallel_ff else None\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        \"\"\"\n",
    "        einstein notation\n",
    "        b - batch\n",
    "        h - heads\n",
    "        n, i, j - sequence length (base sequence length, source, target)\n",
    "        d - feature dimension\n",
    "        \"\"\"\n",
    "\n",
    "        # pre-layernorm, for queries and context\n",
    "\n",
    "        x = self.norm(x)\n",
    "        context = self.context_norm(context)\n",
    "\n",
    "        # get queries\n",
    "\n",
    "        q = self.to_q(x)\n",
    "        q = rearrange(q, 'b n (h d) -> b h n d', h = self.heads)\n",
    "\n",
    "        # scale\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # get key / values\n",
    "\n",
    "        k, v = self.to_kv(context).chunk(2, dim=-1)\n",
    "\n",
    "        # query / key similarity\n",
    "\n",
    "        sim = einsum('b h i d, b j d -> b h i j', q, k)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True)\n",
    "        attn = sim.softmax(dim=-1)\n",
    "\n",
    "        # aggregate\n",
    "\n",
    "        out = einsum('b h i j, b j d -> b h i d', attn, v)\n",
    "\n",
    "        # merge and combine heads\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        # add parallel feedforward (for multimodal layers)\n",
    "\n",
    "        if exists(self.ff):\n",
    "            out = out + self.ff(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class VideoPooler(nn.Module):\n",
    "    def __init__(self, dim, context_dim, seq_len, heads, dim_head, proj_dim=None):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = PositionalEncoding(dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(dim))\n",
    "\n",
    "        self.img_queries = nn.Parameter(torch.randn(seq_len + 1, dim)) # num image queries for multimodal, but 1 extra CLS for contrastive learning\n",
    "        self.img_attn_pool = CrossAttention(dim=dim, context_dim=dim, dim_head=dim_head, heads=heads, norm_context=True)\n",
    "        self.img_attn_pool_norm = LayerNorm(dim)\n",
    "        \n",
    "        self.proj = None if proj_dim is None else nn.Sequential(\n",
    "            nn.Linear(dim, (dim+proj_dim)//2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear((dim+proj_dim)//2, proj_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        cls_tokens = repeat(self.cls_token, 'd -> b 1 d', b=x.shape[0])\n",
    "        x = torch.cat((cls_tokens, x), dim=-2)\n",
    "        \n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        img_queries = repeat(self.img_queries, 'n d -> b n d', b=x.shape[0])\n",
    "        img_queries = self.img_attn_pool(img_queries, x)\n",
    "        img_queries = self.img_attn_pool_norm(img_queries)\n",
    "        \n",
    "        video_embedding = img_queries[:, 0]\n",
    "        pred = video_embedding\n",
    "        if self.proj is not None:\n",
    "            pred = self.proj(video_embedding)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4a8f0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/iejmac/wds_kinetics\"\n",
    "splits = pd.read_csv(os.path.join(DATA_DIR, \"splits.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "96e04aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tars = splits[splits[\"split\"] == \"train\"][\"tar_file\"].tolist()\n",
    "val_tars = splits[splits[\"split\"] == \"val\"][\"tar_file\"].tolist()\n",
    "\n",
    "train_tars_paths = [os.path.join(DATA_DIR, t + \".tar\") for t in train_tars]\n",
    "val_tars_paths = [os.path.join(DATA_DIR, t + \".tar\") for t in val_tars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "520aee18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = pd.read_csv(os.path.join(DATA_DIR, \"annotations/train.csv\"))[\"label\"].unique().tolist()\n",
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f86b7b1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c3c36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PARAMS:\n",
    "DIM = 512\n",
    "DEPTH = 12\n",
    "HEADS = 8\n",
    "DIM_HEAD = 128\n",
    "MLP_DIM = 512\n",
    "PROJ_DIM = 700\n",
    "DROPOUT=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8133d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = VideoPooler(\n",
    "    dim=DIM,\n",
    "    context_dim=DIM,\n",
    "    seq_len=SEQ_LEN,\n",
    "    heads=HEADS,\n",
    "    dim_head=DIM_HEAD,\n",
    "    proj_dim=PROJ_DIM,\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pool = pool.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92bbe8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from open_clip/training/scheduler.py\n",
    "def assign_learning_rate(optimizer, new_lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = new_lr\n",
    "\n",
    "\n",
    "def _warmup_lr(base_lr, warmup_length, step):\n",
    "    return base_lr * (step + 1) / warmup_length\n",
    "\n",
    "\n",
    "def cosine_lr(optimizer, base_lr, warmup_length, steps):\n",
    "    def _lr_adjuster(step):\n",
    "        if step < warmup_length:\n",
    "            lr = _warmup_lr(base_lr, warmup_length, step)\n",
    "        else:\n",
    "            e = step - warmup_length\n",
    "            es = steps - warmup_length\n",
    "            lr = 0.5 * (1 + np.cos(np.pi * e / es)) * base_lr\n",
    "        assign_learning_rate(optimizer, lr)\n",
    "        return lr\n",
    "    return _lr_adjuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "138097e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-4\n",
    "WEIGHT_DECAY = 0.0\n",
    "GRAD_CLIP = 1.0\n",
    "LAMBDA = 0.8\n",
    "EPOCHS = 20\n",
    "\n",
    "WARMUP_STEPS = 1000\n",
    "ALL_STEPS = 120000\n",
    "\n",
    "SEQ_LEN = 25\n",
    "BATCH_SIZE = 128\n",
    "NUM_PREPRO = 6\n",
    "\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f3a66dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(pool.parameters(), lr=LR, weight_decay=0.0)\n",
    "\n",
    "# lr_schedule = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda step: LAMBDA**step)\n",
    "lr_schedule = cosine_lr(opt, LR, WARMUP_STEPS, ALL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3c2796ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reader = EmbeddingWebDatasetReader(\n",
    "    urls=val_tars_paths,\n",
    "    standard_seq_len=SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_prepro_workers=NUM_PREPRO,\n",
    "    to_tensor=True,\n",
    "    enable_text=True,\n",
    "    enable_meta=True,\n",
    "    embedding_transform=lambda emb: emb,\n",
    ")\n",
    "\n",
    "train_reader = EmbeddingWebDatasetReader(\n",
    "    urls=train_tars_paths,\n",
    "    standard_seq_len=SEQ_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_prepro_workers=NUM_PREPRO,\n",
    "    to_tensor=True,\n",
    "    enable_text=True,\n",
    "    enable_meta=False,\n",
    "    embedding_transform=lambda emb: emb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7fc9e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0...\n",
      "epoch 0 : step 73999 average loss = 0.6653468614816666\n",
      "epoch 0 : step 74099 average loss = 0.9298540154099464\n",
      "epoch 0 : step 74199 average loss = 0.9315595841407776\n",
      "epoch 0 : step 74299 average loss = 0.9167524462938309\n",
      "epoch 0 : step 74399 average loss = 0.9026793563365936\n",
      "epoch 0 : step 74499 average loss = 0.8978964656591415\n",
      "epoch 0 : step 74599 average loss = 0.9098487958312035\n",
      "epoch 0 : step 74699 average loss = 0.8874560636281967\n",
      "epoch 0 : step 74799 average loss = 0.9201191115379334\n",
      "epoch 0 : step 74899 average loss = 0.9079224413633347\n",
      "epoch 0 : step 74999 average loss = 0.9149649530649185\n",
      "epoch 0 : step 75099 average loss = 0.9329281556606293\n",
      "epoch 0 : step 75199 average loss = 0.8948884096741676\n",
      "epoch 0 : step 75299 average loss = 0.9317408782243729\n",
      "epoch 0 : step 75399 average loss = 0.9159096571803093\n",
      "epoch 0 : step 75499 average loss = 0.9064727365970612\n",
      "epoch 0 : step 75599 average loss = 0.9254825103282929\n",
      "epoch 0 : step 75699 average loss = 0.9249770903587341\n",
      "epoch 0 : step 75799 average loss = 0.9262606805562973\n",
      "epoch 0 : step 75899 average loss = 0.9134557336568833\n",
      "epoch 0 : step 75999 average loss = 0.9191663014888763\n",
      "epoch 0 : step 76099 average loss = 0.9718948096036911\n",
      "epoch 0 : step 76199 average loss = 1.0384810960292816\n",
      "epoch 0 : step 76299 average loss = 1.021923621892929\n",
      "epoch 0 : step 76399 average loss = 0.9942803278565406\n",
      "epoch 0 : step 76499 average loss = 0.9981661814451218\n",
      "epoch 0 : step 76599 average loss = 1.020933439731598\n",
      "epoch 0 : step 76699 average loss = 1.0418343526124954\n",
      "epoch 0 : step 76799 average loss = 1.046308274269104\n",
      "epoch 0 : step 76899 average loss = 1.0394832891225816\n",
      "epoch 0 : step 76999 average loss = 1.0247611981630325\n",
      "epoch 0 : step 77099 average loss = 1.0530259275436402\n",
      "epoch 0 : step 77199 average loss = 1.046140465736389\n",
      "epoch 0 : step 77299 average loss = 1.055016570687294\n",
      "epoch 0 : step 77399 average loss = 1.0514174515008927\n",
      "epoch 0 : step 77499 average loss = 1.0253839772939681\n",
      "epoch 0 : step 77599 average loss = 1.0332426834106445\n",
      "epoch 0 : step 77699 average loss = 1.0543739753961563\n",
      "epoch 0 : step 77799 average loss = 1.088600093126297\n",
      "epoch 0 : step 77899 average loss = 1.0644804006814956\n",
      "epoch 0 : step 77999 average loss = 1.0591768378019333\n",
      "epoch 0 : step 78099 average loss = 1.0602802157402038\n",
      "Epoch 1...\n",
      "epoch 1 : step 78199 average loss = 0.8869869466498495\n",
      "epoch 1 : step 78299 average loss = 0.8805073273181915\n",
      "epoch 1 : step 78399 average loss = 0.9199713844060898\n",
      "epoch 1 : step 78499 average loss = 0.9071338763833046\n",
      "epoch 1 : step 78599 average loss = 0.9007178044319153\n",
      "epoch 1 : step 78699 average loss = 0.9133265620470047\n",
      "epoch 1 : step 78799 average loss = 0.9037271457910537\n",
      "epoch 1 : step 78899 average loss = 0.886463919878006\n",
      "epoch 1 : step 78999 average loss = 0.9244324296712876\n",
      "epoch 1 : step 79099 average loss = 0.8997542804479599\n",
      "epoch 1 : step 79199 average loss = 0.9210137736797332\n",
      "epoch 1 : step 79299 average loss = 0.9273499697446823\n",
      "epoch 1 : step 79399 average loss = 0.8897596192359924\n",
      "epoch 1 : step 79499 average loss = 0.9237759086489677\n",
      "epoch 1 : step 79599 average loss = 0.9083981269598007\n",
      "epoch 1 : step 79699 average loss = 0.9025133508443832\n",
      "epoch 1 : step 79799 average loss = 0.9114537787437439\n",
      "epoch 1 : step 79899 average loss = 0.9246812796592713\n",
      "epoch 1 : step 79999 average loss = 0.9133844363689423\n",
      "epoch 1 : step 80099 average loss = 0.9037783473730088\n",
      "epoch 1 : step 80199 average loss = 0.9093917125463485\n",
      "epoch 1 : step 80299 average loss = 0.9623807495832444\n",
      "epoch 1 : step 80399 average loss = 0.975093686580658\n",
      "epoch 1 : step 80499 average loss = 0.9717207264900207\n",
      "epoch 1 : step 80599 average loss = 0.9571873199939728\n",
      "epoch 1 : step 80699 average loss = 0.9435542595386505\n",
      "epoch 1 : step 80799 average loss = 0.9737298679351807\n",
      "epoch 1 : step 80899 average loss = 1.0032752734422683\n",
      "epoch 1 : step 80999 average loss = 1.0002195519208907\n",
      "epoch 1 : step 81099 average loss = 0.9977940928936004\n",
      "epoch 1 : step 81199 average loss = 0.9799736618995667\n",
      "epoch 1 : step 81299 average loss = 1.021626992225647\n",
      "epoch 1 : step 81399 average loss = 1.0023990100622178\n",
      "epoch 1 : step 81499 average loss = 1.0149986469745635\n",
      "epoch 1 : step 81599 average loss = 1.0079227823019028\n",
      "epoch 1 : step 81699 average loss = 0.9865594828128814\n",
      "epoch 1 : step 81799 average loss = 0.9871015959978103\n",
      "epoch 1 : step 81899 average loss = 1.0221472960710525\n",
      "epoch 1 : step 81999 average loss = 1.0406355279684067\n",
      "epoch 1 : step 82099 average loss = 1.034303360581398\n",
      "epoch 1 : step 82199 average loss = 1.0188711315393448\n",
      "epoch 1 : step 82299 average loss = 1.0178552001714707\n",
      "Epoch 2...\n",
      "epoch 2 : step 82399 average loss = 0.8727828811854124\n",
      "epoch 2 : step 82499 average loss = 0.8507626947760581\n",
      "epoch 2 : step 82599 average loss = 0.9032288265228271\n",
      "epoch 2 : step 82699 average loss = 0.8929433161020279\n",
      "epoch 2 : step 82799 average loss = 0.8798145240545273\n",
      "epoch 2 : step 82899 average loss = 0.907724769115448\n",
      "epoch 2 : step 82999 average loss = 0.8809406691789627\n",
      "epoch 2 : step 83099 average loss = 0.8828621715307235\n",
      "epoch 2 : step 83199 average loss = 0.9053573036193847\n",
      "epoch 2 : step 83299 average loss = 0.8845172542333603\n",
      "epoch 2 : step 83399 average loss = 0.9085269379615784\n",
      "epoch 2 : step 83499 average loss = 0.9059395772218705\n",
      "epoch 2 : step 83599 average loss = 0.8802469390630722\n",
      "epoch 2 : step 83699 average loss = 0.9086720597743988\n",
      "epoch 2 : step 83799 average loss = 0.894985721707344\n",
      "epoch 2 : step 83899 average loss = 0.8815351855754853\n",
      "epoch 2 : step 83999 average loss = 0.893457461297512\n",
      "epoch 2 : step 84099 average loss = 0.9087136179208756\n",
      "epoch 2 : step 84199 average loss = 0.8955794733762741\n",
      "epoch 2 : step 84299 average loss = 0.8930584508180618\n",
      "epoch 2 : step 84399 average loss = 0.8835005193948746\n",
      "epoch 2 : step 84499 average loss = 0.9463365370035172\n",
      "epoch 2 : step 84599 average loss = 0.9367109996080398\n",
      "epoch 2 : step 84699 average loss = 0.9416518497467041\n",
      "epoch 2 : step 84799 average loss = 0.9302156990766526\n",
      "epoch 2 : step 84899 average loss = 0.9115639472007752\n",
      "epoch 2 : step 84999 average loss = 0.952560510635376\n",
      "epoch 2 : step 85099 average loss = 0.9744889259338378\n",
      "epoch 2 : step 85199 average loss = 0.9688609379529953\n",
      "epoch 2 : step 85299 average loss = 0.9735638666152954\n",
      "epoch 2 : step 85399 average loss = 0.9479922759532928\n",
      "epoch 2 : step 85499 average loss = 1.000505347251892\n",
      "epoch 2 : step 85599 average loss = 0.9647798734903336\n",
      "epoch 2 : step 85699 average loss = 0.9920513933897018\n",
      "epoch 2 : step 85799 average loss = 0.9810233318805694\n",
      "epoch 2 : step 85899 average loss = 0.9624776864051818\n",
      "epoch 2 : step 85999 average loss = 0.9562957006692886\n",
      "epoch 2 : step 86099 average loss = 0.9972704660892486\n",
      "epoch 2 : step 86199 average loss = 1.0117959117889403\n",
      "epoch 2 : step 86299 average loss = 1.0129599946737289\n",
      "epoch 2 : step 86399 average loss = 0.9842535156011581\n",
      "epoch 2 : step 86499 average loss = 0.987603639960289\n",
      "Epoch 3...\n",
      "epoch 3 : step 86599 average loss = 0.8439015226066112\n",
      "epoch 3 : step 86699 average loss = 0.8455991631746292\n",
      "epoch 3 : step 86799 average loss = 0.8780122584104538\n",
      "epoch 3 : step 86899 average loss = 0.8738658964633942\n",
      "epoch 3 : step 86999 average loss = 0.8581778267025948\n",
      "epoch 3 : step 87099 average loss = 0.89350162088871\n",
      "epoch 3 : step 87199 average loss = 0.8657755929231644\n",
      "epoch 3 : step 87299 average loss = 0.8703323686122895\n",
      "epoch 3 : step 87399 average loss = 0.8856310838460922\n",
      "epoch 3 : step 87499 average loss = 0.8653506267070771\n",
      "epoch 3 : step 87599 average loss = 0.9002981984615326\n",
      "epoch 3 : step 87699 average loss = 0.8803479814529419\n",
      "epoch 3 : step 87799 average loss = 0.8683201399445534\n",
      "epoch 3 : step 87899 average loss = 0.89270412504673\n",
      "epoch 3 : step 87999 average loss = 0.8873566177487373\n",
      "epoch 3 : step 88099 average loss = 0.8602912831306457\n",
      "epoch 3 : step 88199 average loss = 0.8816613167524338\n",
      "epoch 3 : step 88299 average loss = 0.8925768062472343\n",
      "epoch 3 : step 88399 average loss = 0.8830353546142579\n",
      "epoch 3 : step 88499 average loss = 0.8792926305532456\n",
      "epoch 3 : step 88599 average loss = 0.861968284547329\n",
      "epoch 3 : step 88699 average loss = 0.9257001954317093\n",
      "epoch 3 : step 88799 average loss = 0.9189248603582382\n",
      "epoch 3 : step 88899 average loss = 0.9104316926002503\n",
      "epoch 3 : step 88999 average loss = 0.9071279120445251\n",
      "epoch 3 : step 89099 average loss = 0.8817448803782463\n",
      "epoch 3 : step 89199 average loss = 0.9300976306200027\n",
      "epoch 3 : step 89299 average loss = 0.9532816284894943\n",
      "epoch 3 : step 89399 average loss = 0.9417585867643357\n",
      "epoch 3 : step 89499 average loss = 0.954663113951683\n",
      "epoch 3 : step 89599 average loss = 0.9237883949279785\n",
      "epoch 3 : step 89699 average loss = 0.9906267476081848\n",
      "epoch 3 : step 89799 average loss = 0.9389545640349388\n",
      "epoch 3 : step 89899 average loss = 0.9642771184444427\n",
      "epoch 3 : step 89999 average loss = 0.9599379450082779\n",
      "epoch 3 : step 90099 average loss = 0.9390896213054657\n",
      "epoch 3 : step 90199 average loss = 0.9361484742164612\n",
      "epoch 3 : step 90299 average loss = 0.9864935892820358\n",
      "epoch 3 : step 90399 average loss = 0.9846077543497086\n",
      "epoch 3 : step 90499 average loss = 0.9941834217309952\n",
      "epoch 3 : step 90599 average loss = 0.967101799249649\n",
      "epoch 3 : step 90699 average loss = 0.9610243713855744\n",
      "Epoch 4...\n",
      "epoch 4 : step 90799 average loss = 0.8163152325153351\n",
      "epoch 4 : step 90899 average loss = 0.8303058621287346\n",
      "epoch 4 : step 90999 average loss = 0.8684649199247361\n",
      "epoch 4 : step 91099 average loss = 0.8500937712192536\n",
      "epoch 4 : step 91199 average loss = 0.8467344626784324\n",
      "epoch 4 : step 91299 average loss = 0.875627936720848\n",
      "epoch 4 : step 91399 average loss = 0.8460520103573799\n",
      "epoch 4 : step 91499 average loss = 0.8502066022157669\n",
      "epoch 4 : step 91599 average loss = 0.8741504561901092\n",
      "epoch 4 : step 91699 average loss = 0.8569241672754287\n",
      "epoch 4 : step 91799 average loss = 0.8825799036026001\n",
      "epoch 4 : step 91899 average loss = 0.8675105321407318\n",
      "epoch 4 : step 91999 average loss = 0.851389406323433\n",
      "epoch 4 : step 92099 average loss = 0.8806248843669892\n",
      "epoch 4 : step 92199 average loss = 0.8708967128396035\n",
      "epoch 4 : step 92299 average loss = 0.8485443693399429\n",
      "epoch 4 : step 92399 average loss = 0.8743304470181466\n",
      "epoch 4 : step 92499 average loss = 0.8800450855493546\n",
      "epoch 4 : step 92599 average loss = 0.8734788298606873\n",
      "epoch 4 : step 92699 average loss = 0.8626312524080276\n",
      "epoch 4 : step 92799 average loss = 0.8510420358181\n",
      "epoch 4 : step 92899 average loss = 0.9166495561599731\n",
      "epoch 4 : step 92999 average loss = 0.8952071350812912\n",
      "epoch 4 : step 93099 average loss = 0.8801189175248146\n",
      "epoch 4 : step 93199 average loss = 0.9004805064201356\n",
      "epoch 4 : step 93299 average loss = 0.8646823599934578\n",
      "epoch 4 : step 93399 average loss = 0.909482815861702\n",
      "epoch 4 : step 93499 average loss = 0.9302161651849746\n",
      "epoch 4 : step 93599 average loss = 0.9225443476438522\n",
      "epoch 4 : step 93699 average loss = 0.936699292063713\n",
      "epoch 4 : step 93799 average loss = 0.9097816997766495\n",
      "epoch 4 : step 93899 average loss = 0.9512397527694703\n",
      "epoch 4 : step 93999 average loss = 0.9262758719921113\n",
      "epoch 4 : step 94099 average loss = 0.9504547721147537\n",
      "epoch 4 : step 94199 average loss = 0.9386496090888977\n",
      "epoch 4 : step 94299 average loss = 0.9285205453634262\n",
      "epoch 4 : step 94399 average loss = 0.9216087877750396\n",
      "epoch 4 : step 94499 average loss = 0.967620512843132\n",
      "epoch 4 : step 94599 average loss = 0.9744465315341949\n",
      "epoch 4 : step 94699 average loss = 0.9773277318477631\n",
      "epoch 4 : step 94799 average loss = 0.9493361574411392\n",
      "epoch 4 : step 94899 average loss = 0.9471094971895218\n",
      "Epoch 5...\n",
      "epoch 5 : step 94999 average loss = 0.7972627244144678\n",
      "epoch 5 : step 95099 average loss = 0.8283654430508613\n",
      "epoch 5 : step 95199 average loss = 0.8422279211878777\n",
      "epoch 5 : step 95299 average loss = 0.8396592760086059\n",
      "epoch 5 : step 95399 average loss = 0.8295422232151032\n",
      "epoch 5 : step 95499 average loss = 0.8609038141369819\n",
      "epoch 5 : step 95599 average loss = 0.841176238656044\n",
      "epoch 5 : step 95699 average loss = 0.8358926808834076\n",
      "epoch 5 : step 95799 average loss = 0.859872270822525\n",
      "epoch 5 : step 95899 average loss = 0.8334555321931839\n",
      "epoch 5 : step 95999 average loss = 0.8745954906940461\n",
      "epoch 5 : step 96099 average loss = 0.8512078016996384\n",
      "epoch 5 : step 96199 average loss = 0.8363226908445358\n",
      "epoch 5 : step 96299 average loss = 0.8715156275033951\n",
      "epoch 5 : step 96399 average loss = 0.8645509728789329\n",
      "epoch 5 : step 96499 average loss = 0.8338554787635803\n",
      "epoch 5 : step 96599 average loss = 0.8648515284061432\n",
      "epoch 5 : step 96699 average loss = 0.8670193952322006\n",
      "epoch 5 : step 96799 average loss = 0.8689183640480042\n",
      "epoch 5 : step 96899 average loss = 0.8562052303552627\n",
      "epoch 5 : step 96999 average loss = 0.846973585486412\n",
      "epoch 5 : step 97099 average loss = 0.9058647441864014\n",
      "epoch 5 : step 97199 average loss = 0.8816472625732422\n",
      "epoch 5 : step 97299 average loss = 0.8593536788225173\n",
      "epoch 5 : step 97399 average loss = 0.8924084758758545\n",
      "epoch 5 : step 97499 average loss = 0.849482952952385\n",
      "epoch 5 : step 97599 average loss = 0.8987073439359665\n",
      "epoch 5 : step 97699 average loss = 0.9126800447702408\n",
      "epoch 5 : step 97799 average loss = 0.9037199050188065\n",
      "epoch 5 : step 97899 average loss = 0.9255699974298477\n",
      "epoch 5 : step 97999 average loss = 0.8954762548208237\n",
      "epoch 5 : step 98099 average loss = 0.927824953198433\n",
      "epoch 5 : step 98199 average loss = 0.9088575828075409\n",
      "epoch 5 : step 98299 average loss = 0.9368898463249207\n",
      "epoch 5 : step 98399 average loss = 0.9245146650075913\n",
      "epoch 5 : step 98499 average loss = 0.9192498862743378\n",
      "epoch 5 : step 98599 average loss = 0.9041425347328186\n",
      "epoch 5 : step 98699 average loss = 0.9570273780822753\n",
      "epoch 5 : step 98799 average loss = 0.9647927182912827\n",
      "epoch 5 : step 98899 average loss = 0.9611015003919602\n",
      "epoch 5 : step 98999 average loss = 0.9414656412601471\n",
      "epoch 5 : step 99099 average loss = 0.9421939283609391\n",
      "Epoch 6...\n",
      "epoch 6 : step 99199 average loss = 0.7808604852482677\n",
      "epoch 6 : step 99299 average loss = 0.8115035471320152\n",
      "epoch 6 : step 99399 average loss = 0.8390120252966881\n",
      "epoch 6 : step 99499 average loss = 0.8320209285616875\n",
      "epoch 6 : step 99599 average loss = 0.822545072734356\n",
      "epoch 6 : step 99699 average loss = 0.8489412975311279\n",
      "epoch 6 : step 99799 average loss = 0.8346480014920235\n",
      "epoch 6 : step 99899 average loss = 0.8266582453250885\n",
      "epoch 6 : step 99999 average loss = 0.8471052342653275\n",
      "epoch 6 : step 100099 average loss = 0.8249582293629646\n",
      "epoch 6 : step 100199 average loss = 0.8640274941921234\n",
      "epoch 6 : step 100299 average loss = 0.8404279923439026\n",
      "epoch 6 : step 100399 average loss = 0.829319489300251\n",
      "epoch 6 : step 100499 average loss = 0.8548406594991684\n",
      "epoch 6 : step 100599 average loss = 0.8510140424966812\n",
      "epoch 6 : step 100699 average loss = 0.832928446829319\n",
      "epoch 6 : step 100799 average loss = 0.8472570043802261\n",
      "epoch 6 : step 100899 average loss = 0.859249079823494\n",
      "epoch 6 : step 100999 average loss = 0.8602827799320221\n",
      "epoch 6 : step 101099 average loss = 0.8532964545488357\n",
      "epoch 6 : step 101199 average loss = 0.8368855199217796\n",
      "epoch 6 : step 101299 average loss = 0.9065083968639374\n",
      "epoch 6 : step 101399 average loss = 0.8710598510503769\n",
      "epoch 6 : step 101499 average loss = 0.8393513444066047\n",
      "epoch 6 : step 101599 average loss = 0.8930730932950973\n",
      "epoch 6 : step 101699 average loss = 0.8438908073306084\n",
      "epoch 6 : step 101799 average loss = 0.8918874460458756\n",
      "epoch 6 : step 101899 average loss = 0.906537230014801\n",
      "epoch 6 : step 101999 average loss = 0.8874503475427628\n",
      "epoch 6 : step 102099 average loss = 0.9164214110374451\n",
      "epoch 6 : step 102199 average loss = 0.8815599638223648\n",
      "epoch 6 : step 102299 average loss = 0.9157350161671638\n",
      "epoch 6 : step 102399 average loss = 0.9037267524003982\n",
      "epoch 6 : step 102499 average loss = 0.9215396213531494\n",
      "epoch 6 : step 102599 average loss = 0.9119349950551987\n",
      "epoch 6 : step 102699 average loss = 0.9119582796096801\n",
      "epoch 6 : step 102799 average loss = 0.883233894109726\n",
      "epoch 6 : step 102899 average loss = 0.9567038786411285\n",
      "epoch 6 : step 102999 average loss = 0.9466427767276764\n",
      "epoch 6 : step 103099 average loss = 0.9551956754922867\n",
      "epoch 6 : step 103199 average loss = 0.9355197495222092\n",
      "epoch 6 : step 103299 average loss = 0.9234728026390076\n",
      "Epoch 7...\n",
      "epoch 7 : step 103399 average loss = 0.7781339044496417\n",
      "epoch 7 : step 103499 average loss = 0.8053769648075104\n",
      "epoch 7 : step 103599 average loss = 0.8330930316448212\n",
      "epoch 7 : step 103699 average loss = 0.8218729138374329\n",
      "epoch 7 : step 103799 average loss = 0.8229164576530457\n",
      "epoch 7 : step 103899 average loss = 0.8391568925976753\n",
      "epoch 7 : step 103999 average loss = 0.8378709629178047\n",
      "epoch 7 : step 104099 average loss = 0.8129922771453857\n",
      "epoch 7 : step 104199 average loss = 0.849546874165535\n",
      "epoch 7 : step 104299 average loss = 0.8188089701533318\n",
      "epoch 7 : step 104399 average loss = 0.858033185005188\n",
      "epoch 7 : step 104499 average loss = 0.82940744638443\n",
      "epoch 7 : step 104599 average loss = 0.8315684762597084\n",
      "epoch 7 : step 104699 average loss = 0.8427328756451606\n",
      "epoch 7 : step 104799 average loss = 0.8413720327615738\n",
      "epoch 7 : step 104899 average loss = 0.8234762719273567\n",
      "epoch 7 : step 104999 average loss = 0.838763476908207\n",
      "epoch 7 : step 105099 average loss = 0.8488258877396584\n",
      "epoch 7 : step 105199 average loss = 0.85134007781744\n",
      "epoch 7 : step 105299 average loss = 0.844475964307785\n",
      "epoch 7 : step 105399 average loss = 0.8296622139215469\n",
      "epoch 7 : step 105499 average loss = 0.8985257697105408\n",
      "epoch 7 : step 105599 average loss = 0.8636706018447876\n",
      "epoch 7 : step 105699 average loss = 0.8296292114257813\n",
      "epoch 7 : step 105799 average loss = 0.8910366573929787\n",
      "epoch 7 : step 105899 average loss = 0.8424917176365853\n",
      "epoch 7 : step 105999 average loss = 0.8898832067847252\n",
      "epoch 7 : step 106099 average loss = 0.8982053756713867\n",
      "epoch 7 : step 106199 average loss = 0.8808472013473511\n",
      "epoch 7 : step 106299 average loss = 0.9122103500366211\n",
      "epoch 7 : step 106399 average loss = 0.8736285305023194\n",
      "epoch 7 : step 106499 average loss = 0.906339959204197\n",
      "epoch 7 : step 106599 average loss = 0.9084669536352158\n",
      "epoch 7 : step 106699 average loss = 0.905885217487812\n",
      "epoch 7 : step 106799 average loss = 0.9093740433454514\n",
      "epoch 7 : step 106899 average loss = 0.9001966172456741\n",
      "epoch 7 : step 106999 average loss = 0.8825857323408127\n",
      "epoch 7 : step 107099 average loss = 0.9414682686328888\n",
      "epoch 7 : step 107199 average loss = 0.9389336588978767\n",
      "epoch 7 : step 107299 average loss = 0.9493127512931824\n",
      "epoch 7 : step 107399 average loss = 0.9234547257423401\n",
      "epoch 7 : step 107499 average loss = 0.89022422041744\n",
      "Epoch 8...\n",
      "epoch 8 : step 107599 average loss = 0.795966276563704\n",
      "epoch 8 : step 107699 average loss = 0.7915627697110176\n",
      "epoch 8 : step 107799 average loss = 0.8302837252616883\n",
      "epoch 8 : step 107899 average loss = 0.8252282813191414\n",
      "epoch 8 : step 107999 average loss = 0.8138565874099731\n",
      "epoch 8 : step 108099 average loss = 0.8300230073928833\n",
      "epoch 8 : step 108199 average loss = 0.8338242581486702\n",
      "epoch 8 : step 108299 average loss = 0.814210901260376\n",
      "epoch 8 : step 108399 average loss = 0.8548904347419739\n",
      "epoch 8 : step 108499 average loss = 0.8064900043606759\n",
      "epoch 8 : step 108599 average loss = 0.8507201379537582\n",
      "epoch 8 : step 108699 average loss = 0.8273323747515678\n",
      "epoch 8 : step 108799 average loss = 0.8348208487033844\n",
      "epoch 8 : step 108899 average loss = 0.8342251178622245\n",
      "epoch 8 : step 108999 average loss = 0.8393656772375107\n",
      "epoch 8 : step 109099 average loss = 0.8115908822417259\n",
      "epoch 8 : step 109199 average loss = 0.840144990682602\n",
      "epoch 8 : step 109299 average loss = 0.8423306316137313\n",
      "epoch 8 : step 109399 average loss = 0.8405241191387176\n",
      "epoch 8 : step 109499 average loss = 0.8328591293096542\n",
      "epoch 8 : step 109599 average loss = 0.8316615998744965\n",
      "epoch 8 : step 109699 average loss = 0.8894608527421951\n",
      "epoch 8 : step 109799 average loss = 0.8507253307104111\n",
      "epoch 8 : step 109899 average loss = 0.8271530109643936\n",
      "epoch 8 : step 109999 average loss = 0.8840182831883431\n",
      "epoch 8 : step 110099 average loss = 0.8415683609247208\n",
      "epoch 8 : step 110199 average loss = 0.8858182057738304\n",
      "epoch 8 : step 110299 average loss = 0.8851158839464187\n",
      "epoch 8 : step 110399 average loss = 0.8799207478761673\n",
      "epoch 8 : step 110499 average loss = 0.9035533839464187\n",
      "epoch 8 : step 110599 average loss = 0.8823902720212936\n",
      "epoch 8 : step 110699 average loss = 0.8905723103880883\n",
      "epoch 8 : step 110799 average loss = 0.9156519985198974\n",
      "epoch 8 : step 110899 average loss = 0.8926398596167564\n",
      "epoch 8 : step 110999 average loss = 0.9046564108133316\n",
      "epoch 8 : step 111099 average loss = 0.8943169564008713\n",
      "epoch 8 : step 111199 average loss = 0.8896915394067765\n",
      "epoch 8 : step 111299 average loss = 0.9294386267662048\n",
      "epoch 8 : step 111399 average loss = 0.9371748134493828\n",
      "epoch 8 : step 111499 average loss = 0.9458367913961411\n",
      "epoch 8 : step 111599 average loss = 0.914751507639885\n",
      "Epoch 9...\n",
      "epoch 9 : step 111699 average loss = 0.8595050629973412\n",
      "epoch 9 : step 111799 average loss = 0.811873942911625\n",
      "epoch 9 : step 111899 average loss = 0.7849016931653022\n",
      "epoch 9 : step 111999 average loss = 0.8258371809124947\n",
      "epoch 9 : step 112099 average loss = 0.8137138849496841\n",
      "epoch 9 : step 112199 average loss = 0.8062702396512031\n",
      "epoch 9 : step 112299 average loss = 0.826092883348465\n",
      "epoch 9 : step 112399 average loss = 0.8208723449707032\n",
      "epoch 9 : step 112499 average loss = 0.8210122591257095\n",
      "epoch 9 : step 112599 average loss = 0.8477918350696564\n",
      "epoch 9 : step 112699 average loss = 0.8032732087373734\n",
      "epoch 9 : step 112799 average loss = 0.8447136819362641\n",
      "epoch 9 : step 112899 average loss = 0.8272311288118362\n",
      "epoch 9 : step 112999 average loss = 0.8316576382517815\n",
      "epoch 9 : step 113099 average loss = 0.8342818582057953\n",
      "epoch 9 : step 113199 average loss = 0.8304226839542389\n",
      "epoch 9 : step 113299 average loss = 0.8033890897035598\n",
      "epoch 9 : step 113399 average loss = 0.8379326725006103\n",
      "epoch 9 : step 113499 average loss = 0.8369306218624115\n",
      "epoch 9 : step 113599 average loss = 0.842415312230587\n",
      "epoch 9 : step 113699 average loss = 0.8253985214233398\n",
      "epoch 9 : step 113799 average loss = 0.8286707937717438\n",
      "epoch 9 : step 113899 average loss = 0.8806182205677032\n",
      "epoch 9 : step 113999 average loss = 0.8463025885820389\n",
      "epoch 9 : step 114099 average loss = 0.822836871445179\n",
      "epoch 9 : step 114199 average loss = 0.8799606478214264\n",
      "epoch 9 : step 114299 average loss = 0.8415305715799332\n",
      "epoch 9 : step 114399 average loss = 0.8804016149044037\n",
      "epoch 9 : step 114499 average loss = 0.8717096269130706\n",
      "epoch 9 : step 114599 average loss = 0.8755619549751281\n",
      "epoch 9 : step 114699 average loss = 0.8999058139324189\n",
      "epoch 9 : step 114799 average loss = 0.8768374025821686\n",
      "epoch 9 : step 114899 average loss = 0.8848184928297996\n",
      "epoch 9 : step 114999 average loss = 0.9098664170503616\n",
      "epoch 9 : step 115099 average loss = 0.8946310809254646\n",
      "epoch 9 : step 115199 average loss = 0.8990088939666748\n",
      "epoch 9 : step 115299 average loss = 0.8901948934793472\n",
      "epoch 9 : step 115399 average loss = 0.8876565265655517\n",
      "epoch 9 : step 115499 average loss = 0.9207275331020355\n",
      "epoch 9 : step 115599 average loss = 0.9383365291357041\n",
      "epoch 9 : step 115699 average loss = 0.9428632199764252\n",
      "epoch 9 : step 115799 average loss = 0.9072278761863708\n",
      "Epoch 10...\n",
      "epoch 10 : step 115899 average loss = 0.8562136264890432\n",
      "epoch 10 : step 115999 average loss = 0.803044168651104\n",
      "epoch 10 : step 116099 average loss = 0.7846832570433616\n",
      "epoch 10 : step 116199 average loss = 0.8203410932421684\n",
      "epoch 10 : step 116299 average loss = 0.814528820514679\n",
      "epoch 10 : step 116399 average loss = 0.7953257980942726\n",
      "epoch 10 : step 116499 average loss = 0.8226875373721123\n",
      "epoch 10 : step 116599 average loss = 0.812225928902626\n",
      "epoch 10 : step 116699 average loss = 0.8156786799430847\n",
      "epoch 10 : step 116799 average loss = 0.8505055683851243\n",
      "epoch 10 : step 116899 average loss = 0.7935852655768394\n",
      "epoch 10 : step 116999 average loss = 0.8346645727753639\n",
      "epoch 10 : step 117099 average loss = 0.8221722117066383\n",
      "epoch 10 : step 117199 average loss = 0.835344352722168\n",
      "epoch 10 : step 117299 average loss = 0.8188304162025452\n",
      "epoch 10 : step 117399 average loss = 0.827293264567852\n",
      "epoch 10 : step 117499 average loss = 0.8030144381523132\n",
      "epoch 10 : step 117599 average loss = 0.8298158743977546\n",
      "epoch 10 : step 117699 average loss = 0.8393747717142105\n",
      "epoch 10 : step 117799 average loss = 0.8450746208429336\n",
      "epoch 10 : step 117899 average loss = 0.8136891108751297\n",
      "epoch 10 : step 117999 average loss = 0.8291411018371582\n",
      "epoch 10 : step 118099 average loss = 0.8830188763141632\n",
      "epoch 10 : step 118199 average loss = 0.8382297712564468\n",
      "epoch 10 : step 118299 average loss = 0.8213843500614166\n",
      "epoch 10 : step 118399 average loss = 0.867373398244381\n",
      "epoch 10 : step 118499 average loss = 0.8434528362751007\n",
      "epoch 10 : step 118599 average loss = 0.8731113761663437\n",
      "epoch 10 : step 118699 average loss = 0.865259171128273\n",
      "epoch 10 : step 118799 average loss = 0.8690338909626008\n",
      "epoch 10 : step 118899 average loss = 0.8945734274387359\n",
      "epoch 10 : step 118999 average loss = 0.8811914736032486\n",
      "epoch 10 : step 119099 average loss = 0.8784635508060455\n",
      "epoch 10 : step 119199 average loss = 0.9091438060998916\n",
      "epoch 10 : step 119299 average loss = 0.8900102818012238\n",
      "epoch 10 : step 119399 average loss = 0.9024571806192399\n",
      "epoch 10 : step 119499 average loss = 0.879616972208023\n",
      "epoch 10 : step 119599 average loss = 0.8957510954141616\n",
      "epoch 10 : step 119699 average loss = 0.9125499600172042\n",
      "epoch 10 : step 119799 average loss = 0.9341581746935844\n",
      "epoch 10 : step 119899 average loss = 0.9443795195221901\n",
      "epoch 10 : step 119999 average loss = 0.9042406332492828\n",
      "Epoch 11...\n",
      "epoch 11 : step 120099 average loss = 0.8468772456422449\n",
      "epoch 11 : step 120199 average loss = 0.8049188941717148\n",
      "epoch 11 : step 120299 average loss = 0.7718563202023506\n",
      "epoch 11 : step 120399 average loss = 0.8095186406373978\n",
      "epoch 11 : step 120499 average loss = 0.8211942040920257\n",
      "epoch 11 : step 120599 average loss = 0.7887962505221366\n",
      "epoch 11 : step 120699 average loss = 0.819102694094181\n",
      "epoch 11 : step 120799 average loss = 0.8119858744740486\n",
      "epoch 11 : step 120899 average loss = 0.8127081400156021\n",
      "epoch 11 : step 120999 average loss = 0.8413661932945251\n",
      "epoch 11 : step 121099 average loss = 0.7951855465769768\n",
      "epoch 11 : step 121199 average loss = 0.8298050403594971\n",
      "epoch 11 : step 121299 average loss = 0.8207202181220055\n",
      "epoch 11 : step 121399 average loss = 0.8280871039628983\n",
      "epoch 11 : step 121499 average loss = 0.8156442233920097\n",
      "epoch 11 : step 121599 average loss = 0.8312070962786674\n",
      "epoch 11 : step 121699 average loss = 0.8034972929954529\n",
      "epoch 11 : step 121799 average loss = 0.8177728685736656\n",
      "epoch 11 : step 121899 average loss = 0.8391712737083435\n",
      "epoch 11 : step 121999 average loss = 0.8444908067584038\n",
      "epoch 11 : step 122099 average loss = 0.814685777425766\n",
      "epoch 11 : step 122199 average loss = 0.8248455661535263\n",
      "epoch 11 : step 122299 average loss = 0.8810714077949524\n",
      "epoch 11 : step 122399 average loss = 0.8393493539094925\n",
      "epoch 11 : step 122499 average loss = 0.8185863503813744\n",
      "epoch 11 : step 122599 average loss = 0.8656364929676056\n",
      "epoch 11 : step 122699 average loss = 0.8419121259450912\n",
      "epoch 11 : step 122799 average loss = 0.8723404008150101\n",
      "epoch 11 : step 122899 average loss = 0.8613354629278183\n",
      "epoch 11 : step 122999 average loss = 0.8666287422180176\n",
      "epoch 11 : step 123099 average loss = 0.8958985257148743\n",
      "epoch 11 : step 123199 average loss = 0.8827598977088928\n",
      "epoch 11 : step 123299 average loss = 0.8807632565498352\n",
      "epoch 11 : step 123399 average loss = 0.9049092888832092\n",
      "epoch 11 : step 123499 average loss = 0.8942651697993278\n",
      "epoch 11 : step 123599 average loss = 0.8900171539187431\n",
      "epoch 11 : step 123699 average loss = 0.8817725414037705\n",
      "epoch 11 : step 123799 average loss = 0.8937260115146637\n",
      "epoch 11 : step 123899 average loss = 0.9102275174856186\n",
      "epoch 11 : step 123999 average loss = 0.9368448737263679\n",
      "epoch 11 : step 124099 average loss = 0.9378765958547592\n",
      "epoch 11 : step 124199 average loss = 0.9083001095056534\n",
      "Epoch 12...\n",
      "epoch 12 : step 124299 average loss = 0.8338315977156162\n",
      "epoch 12 : step 124399 average loss = 0.8096484467387199\n",
      "epoch 12 : step 124499 average loss = 0.7743819004297257\n",
      "epoch 12 : step 124599 average loss = 0.8127274122834206\n",
      "epoch 12 : step 124699 average loss = 0.8206491932272911\n",
      "epoch 12 : step 124799 average loss = 0.7889748275279999\n",
      "epoch 12 : step 124899 average loss = 0.820490898489952\n",
      "epoch 12 : step 124999 average loss = 0.8108612751960754\n",
      "epoch 12 : step 125099 average loss = 0.812418162226677\n",
      "epoch 12 : step 125199 average loss = 0.8456019967794418\n",
      "epoch 12 : step 125299 average loss = 0.8004361516237259\n",
      "epoch 12 : step 125399 average loss = 0.8281872153282166\n",
      "epoch 12 : step 125499 average loss = 0.8156212118268013\n",
      "epoch 12 : step 125599 average loss = 0.838054119348526\n",
      "epoch 12 : step 125699 average loss = 0.8152047097682953\n",
      "epoch 12 : step 125799 average loss = 0.8309628093242645\n",
      "epoch 12 : step 125899 average loss = 0.8074739533662796\n",
      "epoch 12 : step 125999 average loss = 0.8165539157390594\n",
      "epoch 12 : step 126099 average loss = 0.8392944338917733\n",
      "epoch 12 : step 126199 average loss = 0.8460556995868683\n",
      "epoch 12 : step 126299 average loss = 0.8069432470202446\n",
      "epoch 12 : step 126399 average loss = 0.8229991400241852\n",
      "epoch 12 : step 126499 average loss = 0.884399202466011\n",
      "epoch 12 : step 126599 average loss = 0.8469221591949463\n",
      "epoch 12 : step 126699 average loss = 0.8193065330386162\n",
      "epoch 12 : step 126799 average loss = 0.8710692855715751\n",
      "epoch 12 : step 126899 average loss = 0.8408321982622147\n",
      "epoch 12 : step 126999 average loss = 0.8714558392763138\n",
      "epoch 12 : step 127099 average loss = 0.8716053676605224\n",
      "epoch 12 : step 127199 average loss = 0.8659532874822616\n",
      "epoch 12 : step 127299 average loss = 0.8903359735012054\n",
      "epoch 12 : step 127399 average loss = 0.886104844212532\n",
      "epoch 12 : step 127499 average loss = 0.885100861787796\n",
      "epoch 12 : step 127599 average loss = 0.8976518550515175\n",
      "epoch 12 : step 127699 average loss = 0.8981783264875411\n",
      "epoch 12 : step 127799 average loss = 0.889550715982914\n",
      "epoch 12 : step 127899 average loss = 0.8806559282541275\n",
      "epoch 12 : step 127999 average loss = 0.8975533694028854\n",
      "epoch 12 : step 128099 average loss = 0.9080762231349945\n",
      "epoch 12 : step 128199 average loss = 0.9387862196564675\n",
      "epoch 12 : step 128299 average loss = 0.9378459089994431\n",
      "epoch 12 : step 128399 average loss = 0.9114866521954537\n",
      "Epoch 13...\n",
      "epoch 13 : step 128499 average loss = 0.8287954698130489\n",
      "epoch 13 : step 128599 average loss = 0.805750866830349\n",
      "epoch 13 : step 128699 average loss = 0.7774971005320549\n",
      "epoch 13 : step 128799 average loss = 0.8174913087487221\n",
      "epoch 13 : step 128899 average loss = 0.8256163349747658\n",
      "epoch 13 : step 128999 average loss = 0.785113542675972\n",
      "epoch 13 : step 129099 average loss = 0.8229791602492332\n",
      "epoch 13 : step 129199 average loss = 0.8097533005475998\n",
      "epoch 13 : step 129299 average loss = 0.8145671743154526\n",
      "epoch 13 : step 129399 average loss = 0.8495474699139595\n",
      "epoch 13 : step 129499 average loss = 0.8038696748018265\n",
      "epoch 13 : step 129599 average loss = 0.8340920263528824\n",
      "epoch 13 : step 129699 average loss = 0.8123805102705955\n",
      "epoch 13 : step 129799 average loss = 0.8421587932109833\n",
      "epoch 13 : step 129899 average loss = 0.8187733766436577\n",
      "epoch 13 : step 129999 average loss = 0.8202815443277359\n",
      "epoch 13 : step 130099 average loss = 0.8125115686655044\n",
      "epoch 13 : step 130199 average loss = 0.8161118897795677\n",
      "epoch 13 : step 130299 average loss = 0.8396821677684784\n",
      "epoch 13 : step 130399 average loss = 0.8487409076094627\n",
      "epoch 13 : step 130499 average loss = 0.8066565871238709\n",
      "epoch 13 : step 130599 average loss = 0.8237611573934555\n",
      "epoch 13 : step 130699 average loss = 0.8840570628643036\n",
      "epoch 13 : step 130799 average loss = 0.8475751948356628\n",
      "epoch 13 : step 130899 average loss = 0.819808398783207\n",
      "epoch 13 : step 130999 average loss = 0.8755117890238762\n",
      "epoch 13 : step 131099 average loss = 0.8405973881483078\n",
      "epoch 13 : step 131199 average loss = 0.8706456044316292\n",
      "epoch 13 : step 131299 average loss = 0.8760341525077819\n",
      "epoch 13 : step 131399 average loss = 0.8653178083896637\n",
      "epoch 13 : step 131499 average loss = 0.8842134314775467\n",
      "epoch 13 : step 131599 average loss = 0.8974738091230392\n",
      "epoch 13 : step 131699 average loss = 0.8805923211574554\n",
      "epoch 13 : step 131799 average loss = 0.902165770828724\n",
      "epoch 13 : step 131899 average loss = 0.8923737132549285\n",
      "epoch 13 : step 131999 average loss = 0.8940773382782936\n",
      "epoch 13 : step 132099 average loss = 0.8833497351408005\n",
      "epoch 13 : step 132199 average loss = 0.8985273915529252\n",
      "epoch 13 : step 132299 average loss = 0.9032005971670151\n",
      "epoch 13 : step 132399 average loss = 0.9332565236091613\n",
      "epoch 13 : step 132499 average loss = 0.9413367313146591\n",
      "epoch 13 : step 132599 average loss = 0.9111449176073074\n",
      "Epoch 14...\n",
      "epoch 14 : step 132699 average loss = 0.8273363304883241\n",
      "epoch 14 : step 132799 average loss = 0.8009103712439537\n",
      "epoch 14 : step 132899 average loss = 0.779675969183445\n",
      "epoch 14 : step 132999 average loss = 0.8244182088971138\n",
      "epoch 14 : step 133099 average loss = 0.8184697332978249\n",
      "epoch 14 : step 133199 average loss = 0.7936236152052879\n",
      "epoch 14 : step 133299 average loss = 0.8220241391658782\n",
      "epoch 14 : step 133399 average loss = 0.805010833144188\n",
      "epoch 14 : step 133499 average loss = 0.8189847415685654\n",
      "epoch 14 : step 133599 average loss = 0.8419491851329803\n",
      "epoch 14 : step 133699 average loss = 0.8085010346770286\n",
      "epoch 14 : step 133799 average loss = 0.8379535970091819\n",
      "epoch 14 : step 133899 average loss = 0.8100262194871902\n",
      "epoch 14 : step 133999 average loss = 0.8307362964749336\n",
      "epoch 14 : step 134099 average loss = 0.8257839393615722\n",
      "epoch 14 : step 134199 average loss = 0.8187550914287567\n",
      "epoch 14 : step 134299 average loss = 0.8100063425302505\n",
      "epoch 14 : step 134399 average loss = 0.8182909426093101\n",
      "epoch 14 : step 134499 average loss = 0.8374821472167969\n",
      "epoch 14 : step 134599 average loss = 0.8518172714114189\n",
      "epoch 14 : step 134699 average loss = 0.8036096292734146\n",
      "epoch 14 : step 134799 average loss = 0.8289516374468804\n",
      "epoch 14 : step 134899 average loss = 0.8876859658956527\n",
      "epoch 14 : step 134999 average loss = 0.846473280787468\n",
      "epoch 14 : step 135099 average loss = 0.8199054756760598\n",
      "epoch 14 : step 135199 average loss = 0.8708803361654281\n",
      "epoch 14 : step 135299 average loss = 0.8333615300059318\n",
      "epoch 14 : step 135399 average loss = 0.8797169119119644\n",
      "epoch 14 : step 135499 average loss = 0.8793941521644593\n",
      "epoch 14 : step 135599 average loss = 0.8591414231061936\n",
      "epoch 14 : step 135699 average loss = 0.8794600546360016\n",
      "epoch 14 : step 135799 average loss = 0.8953936201334\n",
      "epoch 14 : step 135899 average loss = 0.8783436048030854\n",
      "epoch 14 : step 135999 average loss = 0.90612697660923\n",
      "epoch 14 : step 136099 average loss = 0.8911873972415925\n",
      "epoch 14 : step 136199 average loss = 0.8920669749379158\n",
      "epoch 14 : step 136299 average loss = 0.8779888021945953\n",
      "epoch 14 : step 136399 average loss = 0.9045517981052399\n",
      "epoch 14 : step 136499 average loss = 0.9128435325622558\n",
      "epoch 14 : step 136599 average loss = 0.9301515284180641\n",
      "epoch 14 : step 136699 average loss = 0.927989290356636\n",
      "epoch 14 : step 136799 average loss = 0.9162504261732102\n",
      "Epoch 15...\n",
      "epoch 15 : step 136899 average loss = 0.8208939262852073\n",
      "epoch 15 : step 136999 average loss = 0.8073226755857468\n",
      "epoch 15 : step 137099 average loss = 0.7754631876945496\n",
      "epoch 15 : step 137199 average loss = 0.8275361403822898\n",
      "epoch 15 : step 137299 average loss = 0.8129605385661125\n",
      "epoch 15 : step 137399 average loss = 0.7920350527763367\n",
      "epoch 15 : step 137499 average loss = 0.8247957792878151\n",
      "epoch 15 : step 137599 average loss = 0.8015443593263626\n",
      "epoch 15 : step 137699 average loss = 0.8161676907539368\n",
      "epoch 15 : step 137799 average loss = 0.8353972777724266\n",
      "epoch 15 : step 137899 average loss = 0.808036433160305\n",
      "epoch 15 : step 137999 average loss = 0.8311727973818779\n",
      "epoch 15 : step 138099 average loss = 0.8114259195327759\n",
      "epoch 15 : step 138199 average loss = 0.8301936620473862\n",
      "epoch 15 : step 138299 average loss = 0.823455411195755\n",
      "epoch 15 : step 138399 average loss = 0.8159889823198319\n",
      "epoch 15 : step 138499 average loss = 0.812979793548584\n",
      "epoch 15 : step 138599 average loss = 0.8237783825397491\n",
      "epoch 15 : step 138699 average loss = 0.8314440801739693\n",
      "epoch 15 : step 138799 average loss = 0.852623844742775\n",
      "epoch 15 : step 138899 average loss = 0.7985933971405029\n",
      "epoch 15 : step 138999 average loss = 0.830190799832344\n",
      "epoch 15 : step 139099 average loss = 0.8874621295928955\n",
      "epoch 15 : step 139199 average loss = 0.8460881674289703\n",
      "epoch 15 : step 139299 average loss = 0.8193816983699799\n",
      "epoch 15 : step 139399 average loss = 0.8734256803989411\n",
      "epoch 15 : step 139499 average loss = 0.8269877445697784\n",
      "epoch 15 : step 139599 average loss = 0.8801696813106537\n",
      "epoch 15 : step 139699 average loss = 0.8736810600757599\n",
      "epoch 15 : step 139799 average loss = 0.8645535010099411\n",
      "epoch 15 : step 139899 average loss = 0.8789777880907059\n",
      "epoch 15 : step 139999 average loss = 0.8951823151111603\n",
      "epoch 15 : step 140099 average loss = 0.8737876224517822\n",
      "epoch 15 : step 140199 average loss = 0.909676861166954\n",
      "epoch 15 : step 140299 average loss = 0.8785358428955078\n",
      "epoch 15 : step 140399 average loss = 0.8882737416028976\n",
      "epoch 15 : step 140499 average loss = 0.883900328874588\n",
      "epoch 15 : step 140599 average loss = 0.909520965218544\n",
      "epoch 15 : step 140699 average loss = 0.9115371388196946\n",
      "epoch 15 : step 140799 average loss = 0.9234998571872711\n",
      "epoch 15 : step 140899 average loss = 0.9263522282242775\n",
      "epoch 15 : step 140999 average loss = 0.9214460319280624\n",
      "Epoch 16...\n",
      "epoch 16 : step 141099 average loss = 0.8125664411857724\n",
      "epoch 16 : step 141199 average loss = 0.8079265639185905\n",
      "epoch 16 : step 141299 average loss = 0.7786751580238342\n",
      "epoch 16 : step 141399 average loss = 0.8263139879703522\n",
      "epoch 16 : step 141499 average loss = 0.803303679227829\n",
      "epoch 16 : step 141599 average loss = 0.7965606051683426\n",
      "epoch 16 : step 141699 average loss = 0.8120384189486504\n",
      "epoch 16 : step 141799 average loss = 0.8063483813405037\n",
      "epoch 16 : step 141899 average loss = 0.813851426243782\n",
      "epoch 16 : step 141999 average loss = 0.8282317367196083\n",
      "epoch 16 : step 142099 average loss = 0.8098291301727295\n",
      "epoch 16 : step 142199 average loss = 0.8313660207390785\n",
      "epoch 16 : step 142299 average loss = 0.807407660484314\n",
      "epoch 16 : step 142399 average loss = 0.8297656869888306\n",
      "epoch 16 : step 142499 average loss = 0.8223755490779877\n",
      "epoch 16 : step 142599 average loss = 0.8204538449645042\n",
      "epoch 16 : step 142699 average loss = 0.807767548263073\n",
      "epoch 16 : step 142799 average loss = 0.8262384283542633\n",
      "epoch 16 : step 142899 average loss = 0.8266273513436317\n",
      "epoch 16 : step 142999 average loss = 0.8516609644889832\n",
      "epoch 16 : step 143099 average loss = 0.7989642176032067\n",
      "epoch 16 : step 143199 average loss = 0.8357961171865463\n",
      "epoch 16 : step 143299 average loss = 0.8859321534633636\n",
      "epoch 16 : step 143399 average loss = 0.8465395629405975\n",
      "epoch 16 : step 143499 average loss = 0.8136336386203766\n",
      "epoch 16 : step 143599 average loss = 0.865207608640194\n",
      "epoch 16 : step 143699 average loss = 0.8311452493071556\n",
      "epoch 16 : step 143799 average loss = 0.8698792812228203\n",
      "epoch 16 : step 143899 average loss = 0.8747093603014946\n",
      "epoch 16 : step 143999 average loss = 0.8718362432718277\n",
      "epoch 16 : step 144099 average loss = 0.873618580698967\n",
      "epoch 16 : step 144199 average loss = 0.8993074333667755\n",
      "epoch 16 : step 144299 average loss = 0.867882922589779\n",
      "epoch 16 : step 144399 average loss = 0.9070469057559967\n",
      "epoch 16 : step 144499 average loss = 0.8856156146526337\n",
      "epoch 16 : step 144599 average loss = 0.8832121741771698\n",
      "epoch 16 : step 144699 average loss = 0.8840754336118698\n",
      "epoch 16 : step 144799 average loss = 0.9051223134994507\n",
      "epoch 16 : step 144899 average loss = 0.9205204957723617\n",
      "epoch 16 : step 144999 average loss = 0.9249624687433243\n",
      "epoch 16 : step 145099 average loss = 0.9260364264249802\n",
      "epoch 16 : step 145199 average loss = 0.9131308948993683\n",
      "Epoch 17...\n",
      "epoch 17 : step 145299 average loss = 0.8037536808848381\n",
      "epoch 17 : step 145399 average loss = 0.8066033011674881\n",
      "epoch 17 : step 145499 average loss = 0.7789650312066079\n",
      "epoch 17 : step 145599 average loss = 0.8292887723445892\n",
      "epoch 17 : step 145699 average loss = 0.7953608182072639\n",
      "epoch 17 : step 145799 average loss = 0.8048940858244896\n",
      "epoch 17 : step 145899 average loss = 0.8069069984555245\n",
      "epoch 17 : step 145999 average loss = 0.8075064963102341\n",
      "epoch 17 : step 146099 average loss = 0.810594465136528\n",
      "epoch 17 : step 146199 average loss = 0.8258852687478065\n",
      "epoch 17 : step 146299 average loss = 0.8112662440538406\n",
      "epoch 17 : step 146399 average loss = 0.836165058016777\n",
      "epoch 17 : step 146499 average loss = 0.799235211610794\n",
      "epoch 17 : step 146599 average loss = 0.8331326475739479\n",
      "epoch 17 : step 146699 average loss = 0.8205535936355591\n",
      "epoch 17 : step 146799 average loss = 0.822483915090561\n",
      "epoch 17 : step 146899 average loss = 0.8063395875692367\n",
      "epoch 17 : step 146999 average loss = 0.8230711430311203\n",
      "epoch 17 : step 147099 average loss = 0.8284534400701523\n",
      "epoch 17 : step 147199 average loss = 0.8477987146377564\n",
      "epoch 17 : step 147299 average loss = 0.8042687997221947\n",
      "epoch 17 : step 147399 average loss = 0.8375224840641021\n",
      "epoch 17 : step 147499 average loss = 0.8790486657619476\n",
      "epoch 17 : step 147599 average loss = 0.8458453178405761\n",
      "epoch 17 : step 147699 average loss = 0.8127964678406715\n",
      "epoch 17 : step 147799 average loss = 0.8591836076974869\n",
      "epoch 17 : step 147899 average loss = 0.8307496371865273\n",
      "epoch 17 : step 147999 average loss = 0.8699388962984085\n",
      "epoch 17 : step 148099 average loss = 0.8779536882042884\n",
      "epoch 17 : step 148199 average loss = 0.872161363363266\n",
      "epoch 17 : step 148299 average loss = 0.8766971969604492\n",
      "epoch 17 : step 148399 average loss = 0.8932317307591439\n",
      "epoch 17 : step 148499 average loss = 0.8711611452698708\n",
      "epoch 17 : step 148599 average loss = 0.9053739240765571\n",
      "epoch 17 : step 148699 average loss = 0.8885532581806183\n",
      "epoch 17 : step 148799 average loss = 0.8823335471749306\n",
      "epoch 17 : step 148899 average loss = 0.8842214921116829\n",
      "epoch 17 : step 148999 average loss = 0.9101303905248642\n",
      "epoch 17 : step 149099 average loss = 0.913273264169693\n",
      "epoch 17 : step 149199 average loss = 0.9252576833963394\n",
      "epoch 17 : step 149299 average loss = 0.9296443456411362\n",
      "epoch 17 : step 149399 average loss = 0.9051289016008377\n",
      "Epoch 18...\n",
      "epoch 18 : step 149499 average loss = 0.8006795725971461\n",
      "epoch 18 : step 149599 average loss = 0.8045848342776298\n",
      "epoch 18 : step 149699 average loss = 0.7822134587168693\n",
      "epoch 18 : step 149799 average loss = 0.8230011135339736\n",
      "epoch 18 : step 149899 average loss = 0.8014360430836678\n",
      "epoch 18 : step 149999 average loss = 0.8053783366084099\n",
      "epoch 18 : step 150099 average loss = 0.8079183480143547\n",
      "epoch 18 : step 150199 average loss = 0.8024084949493409\n",
      "epoch 18 : step 150299 average loss = 0.816852854192257\n",
      "epoch 18 : step 150399 average loss = 0.8243015271425247\n",
      "epoch 18 : step 150499 average loss = 0.8097052723169327\n",
      "epoch 18 : step 150599 average loss = 0.8457615071535111\n",
      "epoch 18 : step 150699 average loss = 0.79431461840868\n",
      "epoch 18 : step 150799 average loss = 0.8257986921072006\n",
      "epoch 18 : step 150899 average loss = 0.8339408874511719\n",
      "epoch 18 : step 150999 average loss = 0.8137090489268303\n",
      "epoch 18 : step 151099 average loss = 0.8041848480701447\n",
      "epoch 18 : step 151199 average loss = 0.8257102671265603\n",
      "epoch 18 : step 151299 average loss = 0.8344225779175758\n",
      "epoch 18 : step 151399 average loss = 0.8417511290311813\n",
      "epoch 18 : step 151499 average loss = 0.806690562069416\n",
      "epoch 18 : step 151599 average loss = 0.8380581778287888\n",
      "epoch 18 : step 151699 average loss = 0.8778361397981643\n",
      "epoch 18 : step 151799 average loss = 0.8443838959932327\n",
      "epoch 18 : step 151899 average loss = 0.8177050569653511\n",
      "epoch 18 : step 151999 average loss = 0.8521511226892471\n",
      "epoch 18 : step 152099 average loss = 0.8337160661816597\n",
      "epoch 18 : step 152199 average loss = 0.8647556728124619\n",
      "epoch 18 : step 152299 average loss = 0.8882234823703766\n",
      "epoch 18 : step 152399 average loss = 0.8702288466691971\n",
      "epoch 18 : step 152499 average loss = 0.8775003457069397\n",
      "epoch 18 : step 152599 average loss = 0.8938752162456512\n",
      "epoch 18 : step 152699 average loss = 0.8677342355251312\n",
      "epoch 18 : step 152799 average loss = 0.9066641393303871\n",
      "epoch 18 : step 152899 average loss = 0.8897624856233597\n",
      "epoch 18 : step 152999 average loss = 0.8810141554474831\n",
      "epoch 18 : step 153099 average loss = 0.885830717086792\n",
      "epoch 18 : step 153199 average loss = 0.9051724535226822\n",
      "epoch 18 : step 153299 average loss = 0.9172591507434845\n",
      "epoch 18 : step 153399 average loss = 0.9264996814727783\n",
      "epoch 18 : step 153499 average loss = 0.9281470385193825\n",
      "epoch 18 : step 153599 average loss = 0.9042948406934738\n",
      "Epoch 19...\n",
      "epoch 19 : step 153699 average loss = 0.7992976844310761\n",
      "epoch 19 : step 153799 average loss = 0.8009226566553116\n",
      "epoch 19 : step 153899 average loss = 0.7950482600927353\n",
      "epoch 19 : step 153999 average loss = 0.81416473954916\n",
      "epoch 19 : step 154099 average loss = 0.8083369761705399\n",
      "epoch 19 : step 154199 average loss = 0.8053463992476463\n",
      "epoch 19 : step 154299 average loss = 0.8061166226863861\n",
      "epoch 19 : step 154399 average loss = 0.8148113465309144\n",
      "epoch 19 : step 154499 average loss = 0.8086614710092545\n",
      "epoch 19 : step 154599 average loss = 0.8303572380542755\n",
      "epoch 19 : step 154699 average loss = 0.8035217773914337\n",
      "epoch 19 : step 154799 average loss = 0.8489977717399597\n",
      "epoch 19 : step 154899 average loss = 0.7984317338466644\n",
      "epoch 19 : step 154999 average loss = 0.821734836101532\n",
      "epoch 19 : step 155099 average loss = 0.8384570914506912\n",
      "epoch 19 : step 155199 average loss = 0.814463635981083\n",
      "epoch 19 : step 155299 average loss = 0.8071980807185173\n",
      "epoch 19 : step 155399 average loss = 0.8327829539775848\n",
      "epoch 19 : step 155499 average loss = 0.8330269119143486\n",
      "epoch 19 : step 155599 average loss = 0.8361528033018112\n",
      "epoch 19 : step 155699 average loss = 0.810644560456276\n",
      "epoch 19 : step 155799 average loss = 0.8379636815190316\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m lr_schedule(step)\n\u001b[0;32m----> 7\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m labs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([all_labels\u001b[38;5;241m.\u001b[39mindex(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m b[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for e in range(EPOCHS):\n",
    "  print(f\"Epoch {e}...\")\n",
    "  for i, b in enumerate(train_reader):\n",
    "    step += 1\n",
    "    lr_schedule(step)\n",
    "    embeddings = b[\"embeddings\"].float().to(device)\n",
    "    labs = torch.Tensor([all_labels.index(l) for l in b[\"text\"]]).long().to(device)\n",
    "\n",
    "    opt.zero_grad()\n",
    "\n",
    "    pred = pool(embeddings)\n",
    "    loss = loss_f(pred, labs)\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip grads:\n",
    "    torch.nn.utils.clip_grad_norm_(pool.parameters(), GRAD_CLIP)\n",
    "\n",
    "    opt.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "\n",
    "    if (step + 1) % 100 == 0:\n",
    "      print(f\"epoch {e} : step {step} average loss = {running_loss/100}\")\n",
    "      running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "63d973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "all_ = 0\n",
    "with torch.no_grad():\n",
    "  for val_b in val_reader:\n",
    "    embeddings = val_b[\"embeddings\"].float().to(device)\n",
    "    labs = torch.Tensor([all_labels.index(l) for l in val_b[\"text\"]])\n",
    "\n",
    "    pred = pool(embeddings).cpu()\n",
    "    pred_cls = torch.argmax(pred, axis=-1)\n",
    "\n",
    "    all_ += len(labs)\n",
    "    correct += torch.sum(labs == pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c91344e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4709)\n"
     ]
    }
   ],
   "source": [
    "print(correct/all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3060b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4825)\n"
     ]
    }
   ],
   "source": [
    "print(correct/all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5c656f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4753)\n"
     ]
    }
   ],
   "source": [
    "print(correct/all_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7aad79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
